{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import undetected_chromedriver as uc  # For using Chrome browser\n",
    "from selenium.webdriver.common.by import By  # For locating elements\n",
    "import time  # For adding delays\n",
    "import pandas as pd  # For working with dataframes\n",
    "from tqdm.notebook import tqdm  # For progress bar\n",
    "\n",
    "# Initialize empty lists to store data\n",
    "names, locations, websites = [], [], []\n",
    "\n",
    "# Create a ChromeOptions object\n",
    "options = uc.ChromeOptions()\n",
    "\n",
    "# Add the \"--disable-popup-blocking\" argument to the ChromeOptions\n",
    "options.add_argument(\"--disable-popup-blocking\")\n",
    "\n",
    "# Initialize a Chrome browser instance\n",
    "driver = uc.Chrome(options=options)\n",
    "\n",
    "# Maximize the browser window\n",
    "driver.maximize_window()\n",
    "\n",
    "# Open the target website\n",
    "driver.get('https://clutch.co/agencies/digital-marketing?client_type=field_pp_cs_enterprise&client_type=field_pp_cs_midmarket')\n",
    "\n",
    "# Wait for 1 second to allow the page to load\n",
    "time.sleep(1)\n",
    "\n",
    "# Close pop-up\n",
    "driver.find_element(By.XPATH, '/html/body/div/div[1]/div[4]/a[2]').click()\n",
    "\n",
    "# Initialize a variable to keep track of the page number\n",
    "n = 0\n",
    "\n",
    "# Initialize a variable to control the loop\n",
    "next_button_enabled = True\n",
    "\n",
    "# Main loop to scrape data from each page\n",
    "while next_button_enabled:\n",
    "    # Wait for 3 seconds before proceeding\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Find the container element that holds the listings\n",
    "    container1 = driver.find_element(By.XPATH, '//*[@id=\"providers\"]/div[2]/ul')\n",
    "\n",
    "    # Find all the listing elements within the container\n",
    "    listings = container1.find_elements(By.XPATH, './li[@data-position]')\n",
    "\n",
    "    # Loop through each listing\n",
    "    for listing in tqdm(listings):\n",
    "\n",
    "        # Scroll the page to bring the listing into view\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", listing)\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Try to extract the name of the company from the listing\n",
    "        try:\n",
    "            name = listing.find_element(By.XPATH, './/h3[@class=\"company_info\"]').text\n",
    "            names.append(name)\n",
    "        except:\n",
    "            name = None\n",
    "            names.append(name)\n",
    "\n",
    "        # Try to extract the location of the company from the listing\n",
    "        try:\n",
    "            location = listing.find_element(By.XPATH, './/span[@class=\"locality\"]').text\n",
    "            locations.append(location)\n",
    "        except:\n",
    "            location = None\n",
    "            locations.append(location)\n",
    "\n",
    "\n",
    "        # Get the link for the web page and then openning it in a new tab\n",
    "        web_page_link = listing.find_element(By.XPATH, './/h3[@class=\"company_info\"]/a').get_attribute('href')\n",
    "        web_page = driver.execute_script(\"window.open('{}', '_blank');\".format(web_page_link))\n",
    "\n",
    "        # Switch to the new tab\n",
    "        driver.switch_to.window(driver.window_handles[1])\n",
    "\n",
    "        # Add 1 sec delay\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Try to extract the website link from the new tab\n",
    "        try:\n",
    "            website = driver.find_element(By.XPATH, '//a[@title=\"Visit website\"]').get_attribute('href')\n",
    "            websites.append(website)\n",
    "        except:\n",
    "            website = None\n",
    "            websites.append(website)\n",
    "\n",
    "        # Close the new tab\n",
    "        driver.close()\n",
    "\n",
    "        # Switch back to the original tab\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "        # Print the extracted data for the current listing\n",
    "        print(name, \":\", location, \":\", website)\n",
    "\n",
    "    # Check if there is a next page button and click it\n",
    "    try:\n",
    "        next_page = driver.find_element(By.XPATH, '//*[@id=\"providers\"]/nav/ul/li[@class=\"page-item next\"]/a').click()\n",
    "    except:\n",
    "        next_button_enabled = False\n",
    "\n",
    "    # Increment the page number\n",
    "    n += 1\n",
    "\n",
    "    # Print the status of the current page\n",
    "    print(f'page{n}: Done')\n",
    "\n",
    "# Create a pandas DataFrame from the scraped data\n",
    "df = pd.DataFrame(list(zip(names, locations, websites)), columns=[\"Name\", \"Location\", \"Website\"])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"agencies.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# Quit the browser\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
